import argparse
from pathlib import Path
import pandas as pd
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, matthews_corrcoef
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from transformers import AutoModel, AutoTokenizer
from vulnerability_model_distributed import VulnerabilityDataset, VulnerabilityPrediction, log_metrics

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('model', type=str, choices=['llama', 'codebert'])
    parser.add_argument('epoch', type=int)
    args = parser.parse_args()
    filename = f'epoch{args.epoch}{args.model}.pth'
    base_data_dir = Path(__file__).parent.resolve() / 'data'
    outputfile = 'test_results.csv'
    print(filename)
    log_name = filename[:-4]
        
    # Instantiate the model based on .pth being worked on
    if 'llama' in filename:
        base_model_name = 'llama'
        model_name = 'meta-llama/Llama-3.2-1B'
        embedding_dim = 2048
        # This is a gated model, please save your Hugging Face read-only token in token.txt
        with open('token.txt', 'r') as file:
            auth_token = file.read().strip()
        tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=auth_token)
        base_model = AutoModel.from_pretrained(model_name, use_auth_token=auth_token, device_map='auto')
        tokenizer.add_special_tokens({'pad_token': '[PAD]'})
        base_model.resize_token_embeddings(len(tokenizer))
    elif 'bert' in filename:
        base_model_name = 'codebert'
        model_name = 'microsoft/codebert-base'
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        base_model = AutoModel.from_pretrained(model_name, device_map='auto')
        embedding_dim = 768

        
    # Build the dataset and loader
    # Define test data
    test_path = base_data_dir / 'test.csv'
    test_df = pd.read_csv(test_path)
    test_func = test_df['processed_func']
    test_target = test_df['target']
    test_dataset = VulnerabilityDataset(processed_func=test_func, target=test_target, tokenizer=tokenizer)
    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)

    criterion = nn.CrossEntropyLoss()
    test_tp, test_fp, test_fn, test_tn = 0,0,0,0
    test_loss= 0.0
    test_preds, test_labels = [],[]

    # Load the state into the model and test
    model = VulnerabilityPrediction(model_name=base_model_name, model=base_model, embedding_dim=embedding_dim)
    checkpoint = torch.load(filename)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()
    with torch.no_grad():
        for batch_idx, (tokenized_func, label) in enumerate(test_loader):
            input_ids = tokenized_func['input_ids']
            attention_mask = tokenized_func['attention_mask']
            labels = label
            logits = model(input_ids=input_ids, attention_mask=attention_mask)

            loss = criterion(logits, labels)
            test_loss += loss.item()

            preds = (torch.argmax(logits, dim=1)).long()
            true_labels = labels.long()
            test_preds.extend(preds.cpu().numpy())
            test_labels.extend(true_labels.cpu().numpy())
        
            test_tp += ((preds == 1) & (true_labels == 1)).sum().item()
            test_fp += ((preds == 1) & (true_labels == 0)).sum().item()
            test_fn += ((preds == 0) & (true_labels == 1)).sum().item()
            test_tn += ((preds == 0) & (true_labels == 0)).sum().item()

            print(f"Batch [{batch_idx}/{len(test_loader)}], Loss: {loss.item()}")

        avg_test_loss = test_loss / len(test_loader)
        acc = accuracy_score(test_labels, test_preds)
        precision = precision_score(test_labels, test_preds)
        recall = recall_score(test_labels, test_preds)
        f1 = f1_score(test_labels, test_preds)
        mcc = matthews_corrcoef(test_labels, test_preds)
        print(f'Acc: {acc}')
        print(f'Precision: {precision}')
        print(f'Recall: {recall}')
        print(f'F1: {f1}')
        print(f'MCC: {mcc}')
        log_metrics(model_name=log_name, acc=acc, prec=precision, recall=recall, mcc=mcc, f1=f1, tp=test_tp, fp=test_fp, tn=test_tn, fn=test_fn, test_loss=avg_test_loss, filename=outputfile)
