from vulnerability_model_distributed import VulnerabilityPrediction, VulnerabilityDataset
import csv
import pandas as pd
from pathlib import Path
from scipy.stats import wilcoxon
import torch
from torch.utils.data import DataLoader
from transformers import AutoModel, AutoTokenizer

bert_dir = 'epoch4codebert.pth'
llama_dir = 'epoch4llama.pth'
base_data_dir = Path(__file__).parent.resolve() / 'data'
test_path = base_data_dir / 'test.csv'
test_df = pd.read_csv(test_path)
test_func = test_df['processed_func']
test_target = test_df['target']

# CodeBERT
# Load everything we need to evaluate
bert_model_name = 'microsoft/codebert-base'
bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)
bert_model = AutoModel.from_pretrained(bert_model_name, device_map='auto')
bert_dim = 768
bert_dataset = VulnerabilityDataset(processed_func=test_func, target=test_target, tokenizer=bert_tokenizer)
bert_loader = DataLoader(bert_dataset, batch_size=16, shuffle=False)
bert_trained_model = VulnerabilityPrediction(model_name='codebert', model=bert_model, embedding_dim=bert_dim)
checkpoint = torch.load(bert_dir)
bert_trained_model.load_state_dict(checkpoint['model_state_dict'])
bert_trained_model.eval()


print('Bert loaded...')

# Eval loop
all_labels, bert_probs, bert_logits = [], [], []
with torch.no_grad():
    for batch_idx, (tokenized_func, label) in enumerate(bert_loader):
        input_ids = tokenized_func['input_ids']
        attention_mask = tokenized_func['attention_mask']
        labels = label
        logits = bert_trained_model(input_ids=input_ids, attention_mask=attention_mask)
        # Convert from one-hot to probabilities
        probs = torch.softmax(logits, dim=1)

        # Save the bert logits and the labels 
        bert_probs.extend(probs.cpu().tolist())
        true_labels = labels.long()
        bert_logits.extend(logits.cpu().tolist())
        all_labels.extend(true_labels.cpu().numpy())

        print(f"Batch [{batch_idx}/{len(bert_loader)}]")

df_bert = pd.DataFrame({
    "logit": bert_logits,
    "probability": bert_probs,
    "label": all_labels
})

df_bert.to_csv("bert_logits_and_probs_onehot.csv", index=False)

# Ensure model and memory is dumped
del bert_trained_model
del bert_loader
del bert_dataset
del bert_model
del bert_tokenizer
del checkpoint
torch.cuda.empty_cache()

print('Bert dropped...')

# Llama
# Load everything we need to evaluate

# This is a gated model, please save your Hugging Face read-only token in token.txt
with open('token.txt', 'r') as file:
    auth_token = file.read().strip()

llama_model_name = 'meta-llama/Llama-3.2-1B'
llama_tokenizer = AutoTokenizer.from_pretrained(llama_model_name, use_auth_token=auth_token)
llama_model = AutoModel.from_pretrained(llama_model_name, use_auth_token=auth_token, device_map='auto')
llama_dim = 2048
llama_tokenizer.add_special_tokens({'pad_token':['PAD']})
llama_model.resize_token_embeddings(len(llama_tokenizer))
llama_dataset = VulnerabilityDataset(processed_func=test_func, target=test_target, tokenizer=llama_tokenizer)
llama_loader = DataLoader(llama_dataset, batch_size=16, shuffle=False)
llama_trained_model = VulnerabilityPrediction(model_name='llama', model=llama_model, embedding_dim=llama_dim)
checkpoint = torch.load(llama_dir)
llama_trained_model.load_state_dict(checkpoint['model_state_dict'])
llama_trained_model.eval()

print('Llama loaded...')

# Eval loop
llama_probs, llama_logits = [], []
with torch.no_grad():
    for batch_idx, (tokenized_func, label) in enumerate(llama_loader):
        input_ids = tokenized_func['input_ids']
        attention_mask = tokenized_func['attention_mask']
        logits = llama_trained_model(input_ids=input_ids, attention_mask=attention_mask)
        # Convert from one-hot to probabilities
        probs = torch.softmax(logits, dim=1)

        # Save the bert logits and the labels 
        llama_probs.extend(probs.cpu().tolist())
        llama_logits.extend(logits.cpu().tolist())
        print(f"Batch [{batch_idx}/{len(llama_loader)}]")

df_llama = pd.DataFrame({
    "logit": llama_logits,
    "probability": llama_probs,
    "labels": all_labels
})

df_llama.to_csv("llama_logits_and_probs_onehot.csv", index=False)

# Ensure model and memory is dumped
del llama_trained_model
del llama_loader
del llama_dataset
del llama_model
del llama_tokenizer
torch.cuda.empty_cache()

print('Llama dropped...')
print('Running Wilcoxon...')

# Separate our probs based on model and label
llama_0 = [prob for prob, label in zip(llama_probs, all_labels) if label == 0]
llama_1 = [prob for prob, label in zip(llama_probs, all_labels) if label == 1]

bert_0 = [prob for prob, label in zip(bert_probs, all_labels) if label == 0]
bert_1 = [prob for prob, label in zip(bert_probs, all_labels) if label == 1]

# Save all values where models agree on an output
bert_0_agree, llama_0_agree, bert_1_agree, llama_1_agree = [],[],[],[]
for bl0, ll0 in zip(bert_0,llama_0):
    if bl0[0] >= 0.5 and ll0[0] >= 0.5:
        bert_0_agree.append(bl0[0])
        llama_0_agree.append(ll0[0])
for bl1, ll1 in zip(bert_1,llama_1):
    if bl1[1] >= 0.5 and ll1[1] >= 0.5:
        bert_1_agree.append(bl1[1])
        llama_1_agree.append(ll1[1])

# Run Wilcoxon and save the result
# On a given label, we predict that llama would predict with more confidence in 0 or 1. Thus we want to see if Llama > BERT is statistically significant.
stat_0, p_0 = wilcoxon(llama_0_agree, bert_0_agree, alternative='greater')
stat_1, p_1 = wilcoxon(llama_1_agree, bert_1_agree, alternative='greater')

# Write model llama name, model bert name, wilcoxon results into csv
row = ['best_bert', 'best_llama', stat_0, p_0, stat_1, p_1]
try:
    with open('results.csv', mode='x', newline='') as file:
        writer = csv.writer(file)
        writer.writerow(['Bert_model','Llama_model','stat_0','p_0','stat_1','p_1'])
except FileExistsError:
    pass
with open('results.csv', mode='a', newline='') as file:
    writer = csv.writer(file)
    writer.writerow(row)

print('Done!')
